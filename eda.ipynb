{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path):\n",
    "    file_contents = dict()\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith('.txt'):\n",
    "            with open(os.path.join(path, filename), 'r') as f:\n",
    "                content = f.read()\n",
    "                file_contents[filename] = content\n",
    "\n",
    "    print(\"... Reading files in path : \", path)\n",
    "    print(\"Number of files read: \", len(file_contents))\n",
    "\n",
    "    return file_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Reading files in path :  /Users/az/Documents/Stanford/Classes/CS224N/final/argue-better/data/effectiveness/train\n",
      "Number of files read:  4191\n",
      "... Reading files in path :  /Users/az/Documents/Stanford/Classes/CS224N/final/argue-better/data/label/train\n",
      "Number of files read:  15594\n"
     ]
    }
   ],
   "source": [
    "dataroot = '/Users/az/Documents/Stanford/Classes/CS224N/final/argue-better/data/'\n",
    "effectiveness_contents = read_files(os.path.join(dataroot, 'effectiveness/train')) # 4191\n",
    "label_contents = read_files(os.path.join(dataroot, 'label/train')) # 15594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36765 entries, 0 to 36764\n",
      "Data columns (total 5 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   discourse_id             36765 non-null  object\n",
      " 1   essay_id                 36765 non-null  object\n",
      " 2   discourse_text           36765 non-null  object\n",
      " 3   discourse_type           36765 non-null  object\n",
      " 4   discourse_effectiveness  36765 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(dataroot, 'effectiveness/train.csv'))\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19526    4099\n",
       "2380     3808\n",
       "15688    3558\n",
       "25551    3301\n",
       "5679     3135\n",
       "         ... \n",
       "9997        6\n",
       "2909        6\n",
       "22782       6\n",
       "21443       6\n",
       "26718       4\n",
       "Name: discourse_text, Length: 36765, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['discourse_text'].map(lambda x: len(x)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>discourse_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Limiting the usage of cars has personal and pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>With so many things in this world that few peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>It is no secret that morning traffic jams and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0                                     discourse_text\n",
       "0        0  Limiting the usage of cars has personal and pr...\n",
       "1        1  With so many things in this world that few peo...\n",
       "2        2  It is no secret that morning traffic jams and ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = (train[train['discourse_effectiveness'] == 'Effective']\n",
    "         .reset_index()\n",
    "         .reset_index()[['level_0', 'discourse_text']]\n",
    "         .replace(r'\\n',' ', regex=True) \n",
    "        )\n",
    "train['discourse_text'].str.strip()\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       level_0                                     discourse_text\n",
       "0           0  Limiting the usage of cars has personal and pr...\n",
       "1           1  With so many things in this world that few peo...\n",
       "2           2  It is no secret that morning traffic jams and ...\n",
       "3           3  the environment suffers greatly from the many ...\n",
       "4           4  \"Passenger cars are responsible for 12 percent...\n",
       "...       ...                                                ...\n",
       "9321     9321  We as humans need social interaction, that is ...\n",
       "9322     9322  One major difference between regular school an...\n",
       "9323     9323  A significant problem in schools today, is stu...\n",
       "9324     9324  While home schoolÂ give students the opportunit...\n",
       "9325     9325  Technology is a major factor in our world toda...\n",
       "\n",
       "[9326 rows x 2 columns]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75ce6d68b67b</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>a great chance to learn something new</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "      <td>Lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>739a6d00f44a</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Taking other peoples advice and doing what the...</td>\n",
       "      <td>Evidence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "3  75ce6d68b67b  D72CB1C11673   \n",
       "0  a261b6e14276  D72CB1C11673   \n",
       "8  739a6d00f44a  D72CB1C11673   \n",
       "\n",
       "                                      discourse_text discourse_type  \n",
       "3             a great chance to learn something new           Claim  \n",
       "0  Making choices in life can be very difficult. ...           Lead  \n",
       "8  Taking other peoples advice and doing what the...       Evidence  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(os.path.join(dataroot, 'effectiveness/test.csv'))\n",
    "test.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>discourse_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Seeking multiple opinions can help a person ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>it can decrease stress levels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                     discourse_text\n",
       "0      0  Making choices in life can be very difficult. ...\n",
       "1      1  Seeking multiple opinions can help a person ma...\n",
       "2      2                     it can decrease stress levels "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.reset_index()[['index', 'discourse_text']].replace(r'\\n',' ', regex=True) \n",
    "test['discourse_text'].str.strip()\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Retrieval Augmented Generation\n",
    "> * Learn to retrieve a sequence from an existing corpus of human-written prototypes (e.g., dialogue responses)\n",
    "> * Learn to edit the retrieved sequence by adding, removing, and modifying tokens in the prototype â this will still result in a more âhuman-likeâ generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastRAG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "`ColBERT` (dense retriever) \n",
    "1. use NN to encode all documents into representative vectors\n",
    "2. encodes query into a vector and using vector similarity search\n",
    "\n",
    "`PLAID` engine\n",
    "* use a set of filtering steps to improve latency times for ColBERT-based indexes\n",
    "\n",
    "\n",
    "    `PLAIDDocumentStore` document store class\n",
    "    * `collection_path` is the path to the documents collection, in the form of a TSV file with columns being \"id,content,title\" where the title is optional.\n",
    "    * `checkpoint_path` is the path for the encoder model, needed to encode queries into vectors at run time. Could be a local path to a model or a model hosted on HuggingFace hub. In order to use our trained model based on NaturalQuestions, provide the path Intel/ColBERT-NQ; see Model Hub for more details.\n",
    "    * `index_path` location of the indexed documents. The index contains the optimized and compressed vector representation of all the documents. Index can be created by the user given a collection and a checkpoint, or can be specified via a path.\n",
    "\n",
    "`Fusion-in-Decoder` (`FiD`)\n",
    "* transformer-based generative model (based on T5 architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'colbert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/br/ld72h9496vs6sr3jsfw4qkhm0000gn/T/ipykernel_43584/2896042996.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcolbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColBERTConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcolbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCollection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcolbert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIndexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSearcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'colbert'"
     ]
    }
   ],
   "source": [
    "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
    "from colbert.data import Queries, Collection\n",
    "from colbert import Indexer, Searcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = 'data'\n",
    "dataset = 'effective'\n",
    "datasplit = 'train'\n",
    "\n",
    "\n",
    "collection = os.path.join(dataroot, dataset, datasplit, 'collection.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = os.path.join(dataroot, dataset, datasplit, 'questions.search.sample.tsv')\n",
    "with open(queries, 'w') as write_tsv:\n",
    "   write_tsv.write(test.to_csv(sep='\\t', index=False, header=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/az/Documents/Stanford/Classes/CS224N/final/argue-better-fastRAG/data/effective/res_t5.csv')\n",
    "df = df.drop(columns=['idx','res'])\n",
    "df['query'] = df['query'].replace(r'\"',' ', regex=True) \n",
    "queries = os.path.join(dataroot, dataset, datasplit, 'questions.search.test.tsv')\n",
    "with open(queries, 'w') as write_tsv:\n",
    "   write_tsv.write(df.to_csv(sep='\\t', index=False, header=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(collection, 'w') as write_tsv:\n",
    "   write_tsv.write(train.to_csv(sep='\\t', index=False, header=False))\n",
    "\n",
    "with open(queries, 'w') as write_tsv:\n",
    "   write_tsv.write(test.to_csv(sep='\\t', index=False, header=False))\n",
    "\n",
    "tsv_read = pd.read_csv(collection, sep='\\t')\n",
    "tsv_read.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 02, 22:47:17] #> Loading the queries from data/effective/train/questions.search.tsv ...\n",
      "[Mar 02, 22:47:17] #> Got 10 queries. All QIDs are unique.\n",
      "\n",
      "[Mar 02, 22:47:17] #> Loading collection...\n",
      "0M \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Loaded 10 queries and 9,326 passages'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = Queries(path=queries)\n",
    "collection = Collection(path=collection)\n",
    "\n",
    "f'Loaded {len(queries)} queries and {len(collection):,} passages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "from fastrag.stores import PLAIDDocumentStore\n",
    "\n",
    "nbits = 2\n",
    "gpus = 0\n",
    "ranks = 1\n",
    "index_name = f'{dataset}.{datasplit}.{nbits}bits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Mar 02, 23:11:16] #> Note: Output directory effective.train.2bits/ already exists\n",
      "\n",
      "\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n",
      "  File \"/var/folders/br/ld72h9496vs6sr3jsfw4qkhm0000gn/T/ipykernel_42688/3750005940.py\", line 1, in <module>\n",
      "    store = PLAIDDocumentStore(\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/haystack/nodes/base.py\", line 48, in wrapper_exportable_to_yaml\n",
      "    init_func(self, *args, **kwargs)\n",
      "  File \"/Users/az/Documents/Stanford/Classes/CS224N/final/argue-better-fastRAG/fastrag/stores/plaid.py\", line 62, in __init__\n",
      "    self._create_index()\n",
      "  File \"/Users/az/Documents/Stanford/Classes/CS224N/final/argue-better-fastRAG/fastrag/stores/plaid.py\", line 99, in _create_index\n",
      "    indexer.index(\"\", collection=self.collection_path, overwrite=True)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexer.py\", line 77, in index\n",
      "    self.__launch(collection)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexer.py\", line 82, in __launch\n",
      "    manager = mp.Manager()\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/context.py\", line 57, in Manager\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/managers.py\", line 566, in start\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/connection.py\", line 255, in recv\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/connection.py\", line 388, in _recv\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/pygments/styles/__init__.py\", line 78, in get_style_by_name\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2052, in showtraceback\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 799, in format_exception_as_a_whole\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 844, in get_records\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/pygments/styles/__init__.py\", line 80, in get_style_by_name\n",
      "pygments.util.ClassNotFound: Could not find style module 'default', though it should be builtin.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:posthog:error uploading: Could not find a suitable TLS CA certificate bundle, invalid path: /Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/certifi/cacert.pem\n"
     ]
    }
   ],
   "source": [
    "store = PLAIDDocumentStore(\n",
    "    index_path=index_name,\n",
    "    checkpoint_path=\"Intel/ColBERT-NQ\",\n",
    "    collection_path=collection,\n",
    "    create=True,\n",
    "    nbits=nbits,\n",
    "    gpus=gpus,\n",
    "    ranks=ranks,\n",
    "    doc_maxlen=120,\n",
    "    query_maxlen=60,\n",
    "    kmeans_niters=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Mar 01, 18:56:47] #> Note: Output directory /Users/az/Documents/Stanford/Classes/CS224N/final/argue-better/experiments/notebook/indexes/effective.train.2bits already exists\n",
      "\n",
      "\n",
      "#> Starting...\n",
      "#> Starting...\n",
      "WARNING: faiss must be imported for indexing\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 20,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 1e-5,\n",
      "    \"maxsteps\": 400000,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 20000,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 64,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": \"bert-base-uncased\",\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 180,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"downloads\\/colbertv2.0\",\n",
      "    \"triples\": \"\\/future\\/u\\/okhattab\\/root\\/unit\\/experiments\\/2021.10\\/downstream.distillation.round2.2_score\\/round2.nway6.cosine.ib\\/examples.64.json\",\n",
      "    \"collection\": {\n",
      "        \"provenance\": \"data\\/effective\\/train\\/collection.tsv\"\n",
      "    },\n",
      "    \"queries\": \"\\/future\\/u\\/okhattab\\/data\\/MSMARCO\\/queries.train.tsv\",\n",
      "    \"index_name\": \"effective.train.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/Users\\/az\\/Documents\\/Stanford\\/Classes\\/CS224N\\/final\\/argue-better\\/experiments\",\n",
      "    \"experiment\": \"notebook\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2023-03\\/01\\/18.15.18\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 5,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 0\n",
      "}\n",
      "[Mar 01, 18:56:51] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 18:56:51] [0] \t\t # of sampled PIDs = 9326 \t sampled_pids[:3] = [6825, 166, 4892]\n",
      "[Mar 01, 18:56:51] [0] \t\t #> Encoding 1866 passages..\n",
      "#> Starting...\n",
      "WARNING: faiss must be imported for indexing\n",
      "[Mar 01, 18:56:54] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 18:56:54] [1] \t\t #> Encoding 1866 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Starting...\n",
      "WARNING: faiss must be imported for indexing\n",
      "[Mar 01, 18:56:59] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 18:57:00] [2] \t\t #> Encoding 1866 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Starting...\n",
      "WARNING: faiss must be imported for indexing\n",
      "[Mar 01, 18:57:05] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 18:57:05] [3] \t\t #> Encoding 1866 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: faiss must be imported for indexing\n",
      "[Mar 01, 18:57:13] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 18:57:13] [4] \t\t #> Encoding 1862 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "100%|ââââââââââ| 30/30 [20:00<00:00, 40.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 19:16:52] [0] \t\t avg_doclen_est = 68.29689025878906 \t len(local_sample) = 1,866\n",
      "[Mar 01, 19:16:52] [0] \t\t Creaing 8,192 partitions.\n",
      "[Mar 01, 19:16:52] [0] \t\t *Estimated* 636,936 embeddings.\n",
      "[Mar 01, 19:16:52] [0] \t\t #> Saving the indexing plan to /Users/az/Documents/Stanford/Classes/CS224N/final/argue-better/experiments/notebook/indexes/effective.train.2bits/plan.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/infra/launcher.py\", line 117, in setup_new_process\n",
      "    return_val = callee(config, *args)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 31, in encode\n",
      "    encoder.run(shared_lists)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 57, in run\n",
      "    distributed.barrier(self.rank)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/utils/distributed.py\", line 38, in barrier\n",
      "    torch.distributed.barrier(device_ids=[rank % torch.cuda.device_count()])\n",
      "ZeroDivisionError: integer division or modulo by zero\n",
      "100%|ââââââââââ| 30/30 [19:59<00:00, 39.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 19:16:55] [1] \t\t avg_doclen_est = 67.5959243774414 \t len(local_sample) = 1,866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/infra/launcher.py\", line 117, in setup_new_process\n",
      "    return_val = callee(config, *args)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 31, in encode\n",
      "    encoder.run(shared_lists)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 57, in run\n",
      "    distributed.barrier(self.rank)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/utils/distributed.py\", line 38, in barrier\n",
      "    torch.distributed.barrier(device_ids=[rank % torch.cuda.device_count()])\n",
      "ZeroDivisionError: integer division or modulo by zero\n",
      "100%|ââââââââââ| 30/30 [20:07<00:00, 40.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 19:17:08] [2] \t\t avg_doclen_est = 59.00053405761719 \t len(local_sample) = 1,866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/infra/launcher.py\", line 117, in setup_new_process\n",
      "    return_val = callee(config, *args)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 31, in encode\n",
      "    encoder.run(shared_lists)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 57, in run\n",
      "    distributed.barrier(self.rank)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/utils/distributed.py\", line 38, in barrier\n",
      "    torch.distributed.barrier(device_ids=[rank % torch.cuda.device_count()])\n",
      "ZeroDivisionError: integer division or modulo by zero\n",
      "100%|ââââââââââ| 30/30 [20:03<00:00, 40.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 19:17:10] [3] \t\t avg_doclen_est = 59.81671905517578 \t len(local_sample) = 1,866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/infra/launcher.py\", line 117, in setup_new_process\n",
      "    return_val = callee(config, *args)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 31, in encode\n",
      "    encoder.run(shared_lists)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 57, in run\n",
      "    distributed.barrier(self.rank)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/utils/distributed.py\", line 38, in barrier\n",
      "    torch.distributed.barrier(device_ids=[rank % torch.cuda.device_count()])\n",
      "ZeroDivisionError: integer division or modulo by zero\n",
      "100%|ââââââââââ| 30/30 [19:56<00:00, 39.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 19:17:11] [4] \t\t avg_doclen_est = 70.16970825195312 \t len(local_sample) = 1,862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/infra/launcher.py\", line 117, in setup_new_process\n",
      "    return_val = callee(config, *args)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 31, in encode\n",
      "    encoder.run(shared_lists)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 57, in run\n",
      "    distributed.barrier(self.rank)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/utils/distributed.py\", line 38, in barrier\n",
      "    torch.distributed.barrier(device_ids=[rank % torch.cuda.device_count()])\n",
      "ZeroDivisionError: integer division or modulo by zero\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m config \u001b[38;5;241m=\u001b[39m ColBERTConfig(\n\u001b[1;32m      7\u001b[0m     nbits\u001b[38;5;241m=\u001b[39mnbits,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m indexer \u001b[38;5;241m=\u001b[39m Indexer(checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdownloads/colbertv2.0\u001b[39m\u001b[38;5;124m'\u001b[39m, config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexer.py:77\u001b[0m, in \u001b[0;36mIndexer.index\u001b[0;34m(self, name, collection, overwrite)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merase()\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_does_not_exist \u001b[38;5;129;01mor\u001b[39;00m overwrite \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreuse\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_path\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexer.py:87\u001b[0m, in \u001b[0;36mIndexer.__launch\u001b[0;34m(self, collection)\u001b[0m\n\u001b[1;32m     84\u001b[0m shared_queues \u001b[38;5;241m=\u001b[39m [manager\u001b[38;5;241m.\u001b[39mQueue(maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnranks)]\n\u001b[1;32m     86\u001b[0m launcher \u001b[38;5;241m=\u001b[39m Launcher(encode)\n\u001b[0;32m---> 87\u001b[0m \u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_lists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_queues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/infra/launcher.py:78\u001b[0m, in \u001b[0;36mLauncher.launch\u001b[0;34m(self, custom_config, *args)\u001b[0m\n\u001b[1;32m     74\u001b[0m print_memory_stats(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAIN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# TODO: If the processes crash upon join, raise an exception and don't block on .get() below!\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m return_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([return_value_queue\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m all_procs])\n\u001b[1;32m     79\u001b[0m return_values \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m rank, val \u001b[38;5;129;01min\u001b[39;00m return_values]\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_all:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/infra/launcher.py:78\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     74\u001b[0m print_memory_stats(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAIN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# TODO: If the processes crash upon join, raise an exception and don't block on .get() below!\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m return_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([\u001b[43mreturn_value_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m all_procs])\n\u001b[1;32m     79\u001b[0m return_values \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m rank, val \u001b[38;5;129;01min\u001b[39;00m return_values]\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_all:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/queues.py:103\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block \u001b[38;5;129;01mand\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock:\n\u001b[0;32m--> 103\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sem\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/connection.py:221\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/connection.py:419\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 419\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/connection.py:384\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    382\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 384\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with Run().context(RunConfig(nranks=5, experiment='notebook')):\n",
    "\n",
    "    config = ColBERTConfig(\n",
    "        nbits=nbits,\n",
    "    )\n",
    "    indexer = Indexer(checkpoint='downloads/colbertv2.0', config=config)\n",
    "    print(\"start indexing\")\n",
    "    indexer.index(name=index_name, collection=collection, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/az/Documents/Stanford/Classes/CS224N/final/argue-better/experiments/notebook/indexes/effective.train.2bits'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer.get_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 19:27:29] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Mar 01, 19:27:29] #> Loading codec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/az/Documents/Stanford/Classes/CS224N/final/argue-better/experiments/notebook/indexes/effective.train.2bits/centroids.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Run()\u001b[38;5;241m.\u001b[39mcontext(RunConfig(experiment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnotebook\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m----> 2\u001b[0m     searcher \u001b[38;5;241m=\u001b[39m \u001b[43mSearcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/searcher.py:41\u001b[0m, in \u001b[0;36mSearcher.__init__\u001b[0;34m(self, index, checkpoint, collection, config)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_gpu:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mranker \u001b[38;5;241m=\u001b[39m \u001b[43mIndexScorer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m print_memory_stats()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/search/index_storage.py:19\u001b[0m, in \u001b[0;36mIndexScorer.__init__\u001b[0;34m(self, index_path, use_gpu)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index_path, use_gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_gpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     IndexScorer\u001b[38;5;241m.\u001b[39mtry_load_torch_extensions(use_gpu)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings_strided \u001b[38;5;241m=\u001b[39m ResidualEmbeddingsStrided(\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodec, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoclens\n\u001b[1;32m     25\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/search/index_loader.py:18\u001b[0m, in \u001b[0;36mIndexLoader.__init__\u001b[0;34m(self, index_path, use_gpu)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_path \u001b[38;5;241m=\u001b[39m index_path\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_gpu \u001b[38;5;241m=\u001b[39m use_gpu\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_codec\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_ivf()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_doclens()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/search/index_loader.py:26\u001b[0m, in \u001b[0;36mIndexLoader._load_codec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_codec\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     25\u001b[0m     print_message(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#> Loading codec...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodec \u001b[38;5;241m=\u001b[39m \u001b[43mResidualCodec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/codecs/residual.py:132\u001b[0m, in \u001b[0;36mResidualCodec.load\u001b[0;34m(cls, index_path)\u001b[0m\n\u001b[1;32m    129\u001b[0m avgresidual_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(index_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_residual.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    130\u001b[0m buckets_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(index_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuckets.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 132\u001b[0m centroids \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcentroids_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m avg_residual \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(avgresidual_path, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m bucket_cutoffs, bucket_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(buckets_path, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    769\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    773\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    775\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 270\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/az/Documents/Stanford/Classes/CS224N/final/argue-better/experiments/notebook/indexes/effective.train.2bits/centroids.pt'"
     ]
    }
   ],
   "source": [
    "with Run().context(RunConfig(experiment='notebook')):\n",
    "    searcher = Searcher(index=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: faiss must be imported for indexing\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "PLAIDDocumentStore.__init__() missing 1 required positional argument: 'index_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfastrag\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# https://github.com/IntelLabs/fastRAG/blob/main/models.md\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[43mPLAIDDocumentStore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIntel/ColBERT-NQ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcollection_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/train.tsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/haystack/nodes/base.py:48\u001b[0m, in \u001b[0;36mexportable_to_yaml.<locals>.wrapper_exportable_to_yaml\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_component_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m][k] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Call the actuall __init__ function with all the arguments\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m \u001b[43minit_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: PLAIDDocumentStore.__init__() missing 1 required positional argument: 'index_path'"
     ]
    }
   ],
   "source": [
    "from fastrag.stores import PLAIDDocumentStore\n",
    "import fastrag, torch\n",
    "\n",
    "# https://github.com/IntelLabs/fastRAG/blob/main/models.md\n",
    "\n",
    "store = PLAIDDocumentStore(index_path=\"\",\n",
    "                           checkpoint_path=\"downloads/,\n",
    "                           collection_path=collection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrag.retrievers.colbert import ColBERTRetriever\n",
    "retriever = ColBERTRetriever(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the answer\n",
    "res['answers'][0].answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "ac62b4d06facacce709a0ffb09328fa4cc9c954f12b15e7d457565310d842b4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
